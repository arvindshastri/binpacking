{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f21658-40c8-40c9-99d2-ec8c0b42e84f",
   "metadata": {},
   "source": [
    "# Bin Packing Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffdec9-9fcb-4a7b-910e-abecc6352210",
   "metadata": {},
   "source": [
    "- Authors:\n",
    "  - Arvind Shastri, shasta2@mcmaster.ca\n",
    "  - Stanley Nguyen, nguyes44@mcmaster.ca\n",
    "- Group ID on Avenue: 48\n",
    "- Gitlab URL: https://gitlab.cas.mcmaster.ca/shasta2/l2-bin-packing.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb763d5-aa1a-4ef1-a6ba-e3cbaae313aa",
   "metadata": {},
   "source": [
    "## How to use the provided code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0308135-ad12-4563-92b8-45681d3e90a2",
   "metadata": {},
   "source": [
    "_(this section is just here for information, you can get rid of it in your own report)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2166b346-058f-4619-9072-e6fbe608fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from macpacking.reader import DatasetReader, BinppReader\n",
    "from macpacking.model  import Online, Offline\n",
    "import macpacking.algorithms.offline as offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe23917-cc5c-4883-9a2a-581f3fbb2ba4",
   "metadata": {},
   "source": [
    "Now that the business code is imported, we can load an existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21df8c2c-a6fa-434b-88c3-361404872819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: _datasets/binpp/N1C1W1/N1C1W1_B.BPP.txt\n",
      "  - Bin Capacity: 100\n",
      "  - Objects to pack: [8, 8, 12, 13, 13, 14, 15, 17, 18, 19, 20, 23, 30, 37, 37, 39, 40, 43, 43, 44, 44, 50, 51, 61, 61, 62, 62, 63, 66, 67, 69, 70, 71, 72, 75, 76, 76, 79, 83, 83, 88, 92, 92, 93, 93, 97, 97, 97, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "dataset = '_datasets/binpp/N1C1W1/N1C1W1_B.BPP.txt'\n",
    "reader: DatasetReader = BinppReader(dataset)\n",
    "print(f'Dataset: {dataset}')\n",
    "print(f'  - Bin Capacity: {reader.offline()[0]}')\n",
    "print(f'  - Objects to pack: {sorted(reader.offline()[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec54798-4c40-4a2c-a88f-59d6da87975e",
   "metadata": {},
   "source": [
    "Acording to the `oracle.xslx` file, we now that the optimal solution for this case is to use _31_ bins. Let's call the baseline algorithm, which is an offline one, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6358d7c1-1777-4c63-af33-d4ebfea952a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 31\n",
      "[[40], [43, 43, 14], [50, 44], [51, 44], [61], [61, 39], [62], [62, 37], [63, 37], [66], [67], [69], [70, 30], [71], [72, 13, 13], [75, 18], [76, 19], [76, 23], [79, 20], [83, 15], [83, 17], [88, 12], [92, 8], [92, 8], [93], [93], [97], [97], [97], [99], [100]]\n"
     ]
    }
   ],
   "source": [
    "import macpacking.algorithms.baseline as baseline\n",
    "strategy: Offline = baseline.BenMaier()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e4777c-bd24-4d4f-a3bc-8465cc5ec346",
   "metadata": {},
   "source": [
    "So the baseline finds the optimal solution. That's good news! Let's call our very own version of `NextFit`, as an offline algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300c2945-fb05-4ab7-9f63-78568bb2f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 35\n",
      "[[14, 13, 13, 12, 8, 8], [20, 19, 18, 17, 15], [37, 30, 23], [39, 37], [43, 40], [44, 43], [50, 44], [51], [61], [61], [62], [62], [63], [66], [67], [69], [70], [71], [72], [75], [76], [76], [79], [83], [83], [88], [92], [92], [93], [93], [97], [97], [97], [99], [100]]\n"
     ]
    }
   ],
   "source": [
    "import macpacking.algorithms.online as online\n",
    "strategy: Offline = offline.NextFit()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10828372-717e-4a8e-bce5-bdb6781ba33f",
   "metadata": {},
   "source": [
    "Damn it, this algorithm is 4 bins far from the optimal solution! Let's try an online version. Usually, they perform worst, so let's measure it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50de8648-a261-4e84-bc56-14beefccde46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 36\n",
      "[[13, 61], [15, 70], [19], [20, 23], [37, 43, 14], [39], [40, 8, 18], [43], [44], [44, 50], [51, 30], [61], [62], [62, 37], [63, 17, 13], [66], [67], [69], [71], [72], [75], [76], [76, 8, 12], [79], [83], [83], [88], [92], [92], [93], [93], [97], [97], [97], [99], [100]]\n"
     ]
    }
   ],
   "source": [
    "strategy: Online = online.NextFit()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523a4f3-6957-4963-ae74-f0009a66d204",
   "metadata": {},
   "source": [
    "As expected, the online version is worst!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58200e6",
   "metadata": {},
   "source": [
    "## SOLID Codebase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83444d",
   "metadata": {},
   "source": [
    "This codebase follows the open-close principle, particularly in the way it implements\n",
    "the algorithms and readers. As there are abstract base classes \"online\" and \"offline\" that define\n",
    "what methods that any online/offline algorithm should have, this allows the code to \n",
    "be open for extension, as we simply inherit from the \"online\" or \"offline\" class to\n",
    "add the respective algorithm. It is closed for modification as we do not need to \n",
    "modify existing classes to implement a new algorithm.\n",
    "The same applies to readers, as we have the abstract base class \"DatasetReader\"\n",
    "that determines what methods each type of reader should have. This is open for\n",
    "extension because as we add new readers to accomodate for new types of data, we \n",
    "simply inherit from the \"DatasetReader\" class. It is closed for modification as we \n",
    "do not need to modify existing classes to implement a new reader.\n",
    "\n",
    "Each of the individual algorithms follow the single responsibility principle. This \n",
    "is because in the class of each algorithm, there is only one task that the class must\n",
    "accomplish, and that is to provide the process of bin packing (in their respective way).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db334a",
   "metadata": {},
   "source": [
    "## Dimensions of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8eac4b",
   "metadata": {},
   "source": [
    "binpp - For each instance of the bin packing problem, we are provided with a single\n",
    "file. The first line contains the number of items, n. The second line contains\n",
    "the max capacity of each bin, c. The remaining lines contain the weights of \n",
    "each individual object, beginning at object 1 and ending at object n. This structure\n",
    "is reflected in the BinppReader, as we read the first line as the number of objects,\n",
    "the second line as the capacity, then the third line and onward as item weights. \n",
    "The algorithms do not directly use the number of items, n.\n",
    "\n",
    "binpp-hard - Identical to binpp, as we are given a single file for each instance of \n",
    "the bin packing problem. The first line is the number of items, n, second is the \n",
    "max capacity of each bin, c, and every line after contains the weight of item 0\n",
    "to item n. The structure is reflected in the same reader for binpp, BinppReader,\n",
    "as we read the first line as the number of objects, the second line as the capacity,\n",
    "then the third line and onward as item weights. The only difference in this dataset\n",
    "is that the overall values for number of items, max capacity, and average weight \n",
    "are significantly larger than binpp.\n",
    "\n",
    "jburkardt - For each instance of the bin packing problem, we are provided with 3\n",
    "files. The first file (denoted with _c) gives us our max capacity for each bin, c. \n",
    "The second file (denoted with _s) gives us the priority of each item, most priority \n",
    "we interpret is the highest number. The third file (denoted with _w) gives us the \n",
    "weight of each item. This structure is reflected in the JburkardtReader, as we \n",
    "read the first file as our max capacity, the second as our priorities, and the third\n",
    " as our weights. The priorities is not used in the algorithms, as we have \n",
    "pre-implemented Online/Offline abstract base classes that do not accomodate for it \n",
    "via input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9fb67",
   "metadata": {},
   "source": [
    "## Algorithm Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb73a43",
   "metadata": {},
   "source": [
    "First fit - With a given item, we determine its corresponding bin by scanning \n",
    "from left to right among the present bins, and stopping when we are able to \n",
    "place the item into the \n",
    "first bin that it is able to fit in. \n",
    "If we cannot fit the item in an existing bin, we create a new bin and place it there.\n",
    "The goal of first fit is to minimize the number of bins created.\n",
    "We can see that this algorithm is the \n",
    "laziest of the rest, as compared to the other algorithms, \n",
    "it checks the least number of bins to determine which one to \n",
    "put the item in. On the other hand, best and worst fit algorithms have to check \n",
    "all of the bins for each item to determine which bin to insert. \n",
    "This allows us to reason that the average amount of space resulting from first fit \n",
    "is the intermediate of the three algorithms, as the first fit algorithm is not \n",
    "aiming for specifically the most or least remaining space.\n",
    "\n",
    "Best Fit - With a given item, we determine its corresponding bin by scanning fully \n",
    "from left to right among the present bins. We then choose from among the present \n",
    "bins, the bin with the least amount of remaining space. \n",
    "If we cannot fit the item in an existing bin, we create a new bin and place it there.\n",
    "We can observe that for each \n",
    "item, we would have to iterate through and check every present bin to determine the \n",
    "tightest fit. This allows us to reason that the average amount of space from best \n",
    "fit is the least of the three algorithms, as it specifically aims to achieve this \n",
    "goal by putting items in the tightest space available.\n",
    "\n",
    "Worst Fit - With a given item, we determine its corresponding bin by scanning fully \n",
    "from left to right among the present bins. We then choose from among the present \n",
    "bins, the bin with the most amount of remaining space. \n",
    "If we cannot fit the item in an existing bin, we create a new bin and place it there.\n",
    "We can observe that for each \n",
    "item, we would have to iterate through and check every present bin to determine the \n",
    "most free bin. This allows us to reason that the average amount of space from the \n",
    "worst fit is the most of the three algorithms, as it specifically aims to achieve \n",
    "this by putting items in the most free space available.\n",
    "\n",
    "Offline - These algorithms, across the board, perform worse than their online \n",
    "counterparts in terms of the goals each algorithm has in mind. This is due to the \n",
    "nature of offline algorithms, and how they are only able to view one item at a time. \n",
    "This leads to first fit averaging more bins created, best fit creating a larger \n",
    "average bin space, and worst fit creating a smaller average bin space, all in \n",
    "comparison to their online counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217aefb9-4bf5-4975-9e18-95718b2c47ca",
   "metadata": {},
   "source": [
    "## Self-reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646f916-24c0-401a-ac38-7aee03e59bf7",
   "metadata": {},
   "source": [
    "As part of the self-reflection dimension of an experiential course, each member of the group is expected to answer to the following four questions:\n",
    "\n",
    "  - What process did you go through to produce this result? (Backward)\n",
    "  - What were your standards for this piece of work? Did you meet your standards? (Inward)\n",
    "  - What the one thing you particularly want people to notice when they look at your work? (Outward)\n",
    "  - What lessons will you keep from this reading/lecture in your professional practice? (Forward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c49c7c7adfe892c6f055310db548ae336e5488a7d1f083d275a98ade2f5bae36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
