{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f21658-40c8-40c9-99d2-ec8c0b42e84f",
   "metadata": {},
   "source": [
    "# Bin Packing Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffdec9-9fcb-4a7b-910e-abecc6352210",
   "metadata": {},
   "source": [
    "- Authors:\n",
    "  - Arvind Shastri, shasta2@mcmaster.ca\n",
    "  - Stanley Nguyen, nguyes44@mcmaster.ca\n",
    "- Group ID on Avenue: 48\n",
    "- Gitlab URL: https://gitlab.cas.mcmaster.ca/shasta2/l2-bin-packing.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb763d5-aa1a-4ef1-a6ba-e3cbaae313aa",
   "metadata": {},
   "source": [
    "## How to use the provided code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0308135-ad12-4563-92b8-45681d3e90a2",
   "metadata": {},
   "source": [
    "_(this section is just here for information, you can get rid of it in your own report)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2166b346-058f-4619-9072-e6fbe608fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from macpacking.reader import DatasetReader, BinppReader\n",
    "from macpacking.model  import Online, Offline\n",
    "import macpacking.algorithms.offline as offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe23917-cc5c-4883-9a2a-581f3fbb2ba4",
   "metadata": {},
   "source": [
    "Now that the business code is imported, we can load an existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21df8c2c-a6fa-434b-88c3-361404872819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: _datasets/binpp/N1C1W1/N1C1W1_B.BPP.txt\n",
      "  - Bin Capacity: 100\n",
      "  - Objects to pack: [8, 8, 12, 13, 13, 14, 15, 17, 18, 19, 20, 23, 30, 37, 37, 39, 40, 43, 43, 44, 44, 50, 51, 61, 61, 62, 62, 63, 66, 67, 69, 70, 71, 72, 75, 76, 76, 79, 83, 83, 88, 92, 92, 93, 93, 97, 97, 97, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "dataset = '_datasets/binpp/N1C1W1/N1C1W1_B.BPP.txt'\n",
    "reader: DatasetReader = BinppReader(dataset)\n",
    "print(f'Dataset: {dataset}')\n",
    "print(f'  - Bin Capacity: {reader.offline()[0]}')\n",
    "print(f'  - Objects to pack: {sorted(reader.offline()[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec54798-4c40-4a2c-a88f-59d6da87975e",
   "metadata": {},
   "source": [
    "Acording to the `oracle.xslx` file, we now that the optimal solution for this case is to use _31_ bins. Let's call the baseline algorithm, which is an offline one, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6358d7c1-1777-4c63-af33-d4ebfea952a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 31\n",
      "[[40], [43, 43, 14], [50, 44], [51, 44], [61], [61, 39], [62], [62, 37], [63, 37], [66], [67], [69], [70, 30], [71], [72, 13, 13], [75, 18], [76, 19], [76, 23], [79, 20], [83, 15], [83, 17], [88, 12], [92, 8], [92, 8], [93], [93], [97], [97], [97], [99], [100]]\n"
     ]
    }
   ],
   "source": [
    "import macpacking.algorithms.baseline as baseline\n",
    "strategy: Offline = baseline.BenMaier()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e4777c-bd24-4d4f-a3bc-8465cc5ec346",
   "metadata": {},
   "source": [
    "So the baseline finds the optimal solution. That's good news! Let's call our very own version of `NextFit`, as an offline algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300c2945-fb05-4ab7-9f63-78568bb2f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 35\n",
      "[[14, 13, 13, 12, 8, 8], [20, 19, 18, 17, 15], [37, 30, 23], [39, 37], [43, 40], [44, 43], [50, 44], [51], [61], [61], [62], [62], [63], [66], [67], [69], [70], [71], [72], [75], [76], [76], [79], [83], [83], [88], [92], [92], [93], [93], [97], [97], [97], [99], [100]]\n"
     ]
    }
   ],
   "source": [
    "import macpacking.algorithms.online as online\n",
    "strategy: Offline = offline.NextFit()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10828372-717e-4a8e-bce5-bdb6781ba33f",
   "metadata": {},
   "source": [
    "Damn it, this algorithm is 4 bins far from the optimal solution! Let's try an online version. Usually, they perform worst, so let's measure it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50de8648-a261-4e84-bc56-14beefccde46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 36\n",
      "[[13, 61], [15, 70], [19], [20, 23], [37, 43, 14], [39], [40, 8, 18], [43], [44], [44, 50], [51, 30], [61], [62], [62, 37], [63, 17, 13], [66], [67], [69], [71], [72], [75], [76], [76, 8, 12], [79], [83], [83], [88], [92], [92], [93], [93], [97], [97], [97], [99], [100]]\n"
     ]
    }
   ],
   "source": [
    "strategy: Online = online.NextFit()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523a4f3-6957-4963-ae74-f0009a66d204",
   "metadata": {},
   "source": [
    "As expected, the online version is worst!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58200e6",
   "metadata": {},
   "source": [
    "## SOLID Codebase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83444d",
   "metadata": {},
   "source": [
    "This codebase follows the open-close principle, particularly in the way it implements\n",
    "the algorithms and readers. As there are abstract base classes \"online\" and \"offline\" that define\n",
    "what methods that any online/offline algorithm should have, this allows the code to \n",
    "be open for extension, as we simply inherit from the \"online\" or \"offline\" class to\n",
    "add the respective algorithm. It is closed for modification as we do not need to \n",
    "modify existing classes to implement a new algorithm.\n",
    "The same applies to readers, as we have the abstract base class \"DatasetReader\"\n",
    "that determines what methods each type of reader should have. This is open for\n",
    "extension because as we add new readers to accomodate for new types of data, we \n",
    "simply inherit from the \"DatasetReader\" class. It is closed for modification as we \n",
    "do not need to modify existing classes to implement a new reader.\n",
    "\n",
    "Each of the individual algorithms follow the single responsibility principle. This \n",
    "is because in the class of each algorithm, there is only one task that the class must\n",
    "accomplish, and that is to provide the process of bin packing (in their respective way).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db334a",
   "metadata": {},
   "source": [
    "## Dimensions of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8eac4b",
   "metadata": {},
   "source": [
    "binpp - For each instance of the bin packing problem, we are provided with a single\n",
    "file. The first line contains the number of items, n. The second line contains\n",
    "the max capacity of each bin, c. The remaining lines contain the weights of \n",
    "each individual object, beginning at object 1 and ending at object n. This structure\n",
    "is reflected in the BinppReader, as we read the first line as the number of objects,\n",
    "the second line as the capacity, then the third line and onward as item weights. \n",
    "The algorithms do not directly use the number of items, n.\n",
    "\n",
    "binpp-hard - Identical to binpp, as we are given a single file for each instance of \n",
    "the bin packing problem. The first line is the number of items, n, second is the \n",
    "max capacity of each bin, c, and every line after contains the weight of item 0\n",
    "to item n. The structure is reflected in the same reader for binpp, BinppReader,\n",
    "as we read the first line as the number of objects, the second line as the capacity,\n",
    "then the third line and onward as item weights. The only difference in this dataset\n",
    "is that the overall values for number of items, max capacity, and average weight \n",
    "are significantly larger than binpp.\n",
    "\n",
    "jburkardt - For each instance of the bin packing problem, we are provided with 3\n",
    "files. The first file (denoted with _c) gives us our max capacity for each bin, c. \n",
    "The second file (denoted with _s) gives us the priority of each item, most priority \n",
    "we interpret is the highest number. The third file (denoted with _w) gives us the \n",
    "weight of each item. This structure is reflected in the JburkardtReader, as we \n",
    "read the first file as our max capacity, the second as our priorities, and the third\n",
    " as our weights. The priorities is not used in the algorithms, as we have \n",
    "pre-implemented Online/Offline abstract base classes that do not accomodate for it \n",
    "via input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9fb67",
   "metadata": {},
   "source": [
    "## Algorithm Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c63793",
   "metadata": {},
   "source": [
    "### __First Fit__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645a89d",
   "metadata": {},
   "source": [
    "With a given item, we determine its corresponding bin by scanning \n",
    "from left to right among the present bins, and stopping when we are able to \n",
    "place the item into the \n",
    "first bin that it is able to fit in. \n",
    "If we cannot fit the item in an existing bin, we create a new bin and place it there.\n",
    "The goal of first fit is to minimize the number of bins created.\n",
    "We can see that this algorithm is the \n",
    "laziest of the rest, as compared to the other algorithms, \n",
    "it checks the least number of bins to determine which one to \n",
    "put the item in. On the other hand, best and worst fit algorithms have to check \n",
    "all of the bins for each item to determine which bin to insert. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a74bf",
   "metadata": {},
   "source": [
    "#### Average Percentage Usage of Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4ba42",
   "metadata": {},
   "source": [
    "This allows us to reason that the average percentage usage of bins resulting from first fit \n",
    "is the intermediate of the three algorithms, as the first fit algorithm is not \n",
    "aiming for specifically the most or least remaining space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdb81d",
   "metadata": {},
   "source": [
    "#### Execution Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45106121",
   "metadata": {},
   "source": [
    "Compared to the rest of the three algorithms, we can reason from the explanation that First Fit takes the least amount of time. This is because in the worst case for an item, we have to iterate through the entire list of existing bins to find a bin that fits the item. However, in the typical case, we will cut our iteration short as we will, on average, find the fitting bin near the middle. Therefore we will not require a full iteration of existing bins per item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a19f3c",
   "metadata": {},
   "source": [
    "#### Number of Comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52c5ab",
   "metadata": {},
   "source": [
    "Following the same argument as the execution time, First Fit will make the least number of comparisons. This is because for a single item, we will make comparisons up until we find a bin that we can fit the item in. Then we will stop the comparisons for the item. In contrast, Best Fit and Worst Fit must make a number of comparisons proportional to the number of existing bins at that given item. Therefore, First Fit will make the least number of comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab57f86",
   "metadata": {},
   "source": [
    "### __Best Fit__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a50ec1",
   "metadata": {},
   "source": [
    "With a given item, we determine its corresponding bin by scanning fully \n",
    "from left to right among the present bins. We then choose from among the present \n",
    "bins, the bin with the least amount of remaining space. \n",
    "If we cannot fit the item in an existing bin, we create a new bin and place it there.\n",
    "We can observe that for each \n",
    "item, we would have to iterate through and check every present bin to determine the \n",
    "tightest fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb0843",
   "metadata": {},
   "source": [
    "#### Average Percentage Usage of Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27027f1",
   "metadata": {},
   "source": [
    "This allows us to reason that the average percentage usage of bins from best \n",
    "fit is the least of the three algorithms, as it specifically aims to achieve this \n",
    "goal by putting items in the tightest space available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9bc302",
   "metadata": {},
   "source": [
    "#### Execution Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2e665",
   "metadata": {},
   "source": [
    "Compared to the rest of the three algorithms, we can reason from the explanation that Best Fit takes the most amount of time alongside Worst Fit. This is because for each item, we have to fully iterate through the list of existing bins without exception. This leads to a greater number of iterations of the list of existing bins than First Fit. Best and worst fit are roughly equivalent in the number of iterations because the only difference in the algorithms is the comparison of less than, or greater than, which does not change the number of iterations and their durations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb46a85",
   "metadata": {},
   "source": [
    "#### Number of Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ce072",
   "metadata": {},
   "source": [
    "Following the same argument as execution time, Best Fit, alongside Worst Fit, will both make the most number of comparisons. This is because for a single item, we are forced to make comparisons to check every existing bin to find among them, the best fitting bin. In contrast, First Fit is not required to compare against every existing bin. Therefore, Best and Worst Fit will make the greatest number of comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42cadb2",
   "metadata": {},
   "source": [
    "### __Worst Fit__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5aace",
   "metadata": {},
   "source": [
    "With a given item, we determine its corresponding bin by scanning fully \n",
    "from left to right among the present bins. We then choose from among the present \n",
    "bins, the bin with the most amount of remaining space. \n",
    "If we cannot fit the item in an existing bin, we create a new bin and place it there.\n",
    "We can observe that for each \n",
    "item, we would have to iterate through and check every present bin to determine the \n",
    "most free bin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93357b",
   "metadata": {},
   "source": [
    "#### Average Percentage Usage of Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6bee4e",
   "metadata": {},
   "source": [
    "This allows us to reason that the average percentage usage of bins from \n",
    "worst fit is the most of the three algorithms, as it specifically aims to achieve \n",
    "this by putting items in the most free space available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aabe51",
   "metadata": {},
   "source": [
    "#### Execution Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd310c8",
   "metadata": {},
   "source": [
    "Compared to the rest of the three algorithms, we can reason from the explanation that Worst Fit takes the most amount of time alongside Best Fit. This is because for each item, we have to fully iterate through the list of existing bins without exception. This leads to a greater number of iterations of the list of existing bins than First Fit. Best and worst fit are roughly equivalent in the number of iterations because the only difference in the algorithms is the comparison of less than, or greater than, which does not change the number of iterations and their durations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4b0de",
   "metadata": {},
   "source": [
    "#### Number of Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0ae7c",
   "metadata": {},
   "source": [
    "Following the same argument as execution time, Best Fit, alongside Worst Fit, will both make the most number of comparisons. This is because for a single item, we are forced to make comparisons to check every existing bin to find among them, the worst fitting bin. In contrast, First Fit is not required to compare against every existing bin. Therefore, Best and Worst Fit will make the greatest number of comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2b943",
   "metadata": {},
   "source": [
    "### __Offline__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f639a",
   "metadata": {},
   "source": [
    "These algorithms, across the board, perform better than their online \n",
    "counterparts in terms of the goals each algorithm has in mind. This is due to the \n",
    "nature of online algorithms, and how they are only able to view one item at a time. This leads to first fit averaging more bins created, best fit creating a larger \n",
    "average bin space, and worst fit creating a smaller average bin space, all in \n",
    "comparison to their online counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fe7c7",
   "metadata": {},
   "source": [
    "## Execution Time Benchmark Graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e7188",
   "metadata": {},
   "source": [
    "From each dataset (binpp, binpp-hard, jburkardt), we will create a graph that \n",
    "chooses 10 scenarios from the corresponding dataset and compare all the algorithms \n",
    "against each other for that given dataset. \n",
    "Our protocol is relevant because then each algorithm will run against the same \n",
    "sample set, allowing for fairness of the algorithms.\n",
    "In addition, the complexity of the scenarios will remain uniform in a given dataset, \n",
    "rather than comparing algorithms against scenarios from different datasets, which \n",
    "would create a significantly harder to read graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217aefb9-4bf5-4975-9e18-95718b2c47ca",
   "metadata": {},
   "source": [
    "## Self-reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646f916-24c0-401a-ac38-7aee03e59bf7",
   "metadata": {},
   "source": [
    "As part of the self-reflection dimension of an experiential course, each member of the group is expected to answer to the following four questions:\n",
    "\n",
    "  - What process did you go through to produce this result? (Backward)\n",
    "  - What were your standards for this piece of work? Did you meet your standards? (Inward)\n",
    "  - What the one thing you particularly want people to notice when they look at your work? (Outward)\n",
    "  - What lessons will you keep from this reading/lecture in your professional practice? (Forward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c49c7c7adfe892c6f055310db548ae336e5488a7d1f083d275a98ade2f5bae36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
